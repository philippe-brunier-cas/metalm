---
title: "Data Preparation "
subtitle: "metalm"
author: "philippe.brunier@cogne.com"
version: 1.0 
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    css: ./custom.css
    df_print: paged
    gallery: no
    highlight: default
    html_document: null
    lightbox: yes
    number_sections: yes
    self_contained: yes
    thumbnails: no
editor_options:
  chunk_output_type: console
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      warning = FALSE,
                      message = FALSE,
                      error = FALSE,
                      fig.height = 7,
                      fig.width = 10,
                      collapse = TRUE,
                      cols.print=20)
rm(list = ls(all.names = TRUE))

require(dplyr)
require(kableExtra)
require(readr)
require(reticulate)
source('~/dev/metalm/R/function.R')
```

# Load dei dati

Viene creato un database che racchiude le informazioni riassunte per sk. 
E' composto come segue:

+ tempo limite (usura)
+ forza prima passata (usura)
+ forza di picco (usura)
+ chimiche di prodotto 
+ prove meccaniche (trazioni, durezze)

(la mappatura è coerente con le tabelle precedenti) 


carico i file, li mappo e li salvo come pkl

```{python join dati e mappe, include = TRUE}

import pandas as pd
import numpy as np

######## opt

headerpath = '/data/metalm/header/head_opt.csv'
filepath = '/data/metalm/database_opt.csv'
    
#carico l'header

header = pd.read_csv(headerpath,sep=';')
nomi_colonne = list(header.col_name)

# creo il dizionario per i data type 
r,c = header.shape

dict_types = {}
for i in range(0,r):
    dict_types[nomi_colonne[i]] = header.data_type[i]


#carico il csv
try:
    
    df_opt = pd.read_csv(filepath,sep='|',
                       names=nomi_colonne,
                        dtype = dict_types,
                        skiprows=[0],
                       )
except ValueError:
    print('warning!!! --> dtype non preso [%s]' %(filepath.split('/')[-1]))
    df_opt = pd.read_csv(filepath,sep='|',
                       names=nomi_colonne,
                        # dtype = dict_types,
                        skiprows=[0],
                       )    

# ciclo per togliere in \n dalla colonna materiali

new_mat = []
for mat in df_opt.materiale:
  new_mat.append(str(mat).replace('\n',''))

df_opt.materiale = new_mat

df_opt = df_opt.to_pickle('/data/metalm/pickle/opt.pkl')


######## wear

headerpath = '/data/metalm/header/head_wear.csv'
filepath = '/data/metalm/dati_wear.csv'
    
#carico l'header

header = pd.read_csv(headerpath,sep=';')
nomi_colonne = list(header.col_name)

# creo il dizionario per i data type 
r,c = header.shape

dict_types = {}
for i in range(0,r):
    dict_types[nomi_colonne[i]] = header.data_type[i]


#carico il csv
try:
    
    df_wear = pd.read_csv(filepath,sep='|',
                       names=nomi_colonne,
                        dtype = dict_types,
                        skiprows=[0]
                       )
except ValueError:
    print('warning!!! --> dtype non preso [%s]' %(filepath.split('/')[-1]))
    df_wear = pd.read_csv(filepath,sep='|',
                       names=nomi_colonne,
                        # dtype = dict_types,
                        skiprows=[0],
                       )    

df_wear = df_wear.to_pickle('/data/metalm/pickle/wear.pkl')

######## ossidi

headerpath = '/data/metalm/header/head_ox.csv'
filepath = '/data/metalm/tabella_ossidi.csv'
    
#carico l'header

header = pd.read_csv(headerpath,sep=';')
nomi_colonne = list(header.col_name)

# creo il dizionario per i data type 
r,c = header.shape

dict_types = {}
for i in range(0,r):
    dict_types[nomi_colonne[i]] = header.data_type[i]


#carico il csv
try:
    
    df_ox = pd.read_csv(filepath,sep='|',
                       names=nomi_colonne,
                        dtype = dict_types,
                        skiprows=[0],
                       )
except ValueError:
    print('warning!!! --> dtype non preso [%s]' %(filepath.split('/')[-1]))
    df_ox = pd.read_csv(filepath,sep='|',
                       names=nomi_colonne,
                        # dtype = dict_types,
                        skiprows=[0],
                       )    

df_ox = df_ox.to_pickle('/data/metalm/pickle/ossidi.pkl')


######## metallografiche

headerpath = '/data/metalm/header/head_met.csv'
filepath = '/data/metalm/analisi_metallografiche.csv'
    
#carico l'header

header = pd.read_csv(headerpath,sep=';')
nomi_colonne = list(header.col_name)

# creo il dizionario per i data type 
r,c = header.shape

dict_types = {}
for i in range(0,r):
    dict_types[nomi_colonne[i]] = header.data_type[i]


#carico il csv
try:
    
    df_ox = pd.read_csv(filepath,sep='|',
                       names=nomi_colonne,
                        dtype = dict_types,
                        skiprows=[0],na_values='na')
                
except ValueError:
    print('warning!!! --> dtype non preso [%s]' %(filepath.split('/')[-1]))
    df_ox = pd.read_csv(filepath,sep='|',
                       names=nomi_colonne,
                        # dtype = dict_types,
                        skiprows=[0],na_values='na')
                       
for i in range(3,23):
  df_ox[df_ox.columns[i]]=df_ox[df_ox.columns[i]].replace('below_limit',float(0))
  
  #df_met[df_ox.columns[i]]=pd.to_numeric(df_ox[df_ox.columns[i]])
    
df_ox = df_ox[df_ox.sk != 'na']
df_ox = df_ox.to_pickle('/data/metalm/pickle/met.pkl')


```

# join dei dati

estraggo le informazioni d'interesse per le correlazioni.
Il drop dei nan non è stato fatto per mantenere la maggior quantità di dati possibile.

Per il momento consideriamo solo:

+ database_opt
+ analisi_metallografiche

```{python join dei dati}
import pandas as pd
import os
import numpy as np

df_wear = pd.read_pickle('/data/metalm/pickle/wear.pkl')
df_met = pd.read_pickle('/data/metalm/pickle/met.pkl')


dfw = df_wear.groupby('sk').mean()
dfs = df_wear.groupby('sk').std()
dfc = df_wear.groupby('sk').count()

dfw[['std_F0','std_Fmax','std_wear_time']] = dfs[['Fz_iniziale','Fz_peak','tempo_usura']]
dfw['n_prove'] = dfc['Fz_iniziale']

#df_met
dfm = df_met.groupby('sk').mean()
dfs = df_met.groupby('sk').std()
dfc = df_met.groupby('sk').count()

features = [ 'C', 'S', 'P', 'Si', 'Mn', 'Cr', 'Ni', 'Mo', 'Cu', 'Sn', 'V',
       'W', 'Co', 'Ti', 'N2', 'O2 ', 'k2_oa', 'k2_os', 'k2_og',
       'rm', 'rp02']

dfw[features] = dfm[features]


dfw = dfw.reset_index()
dfw['dF_perc'] = (dfw.Fz_peak-dfw.Fz_iniziale)/dfw.Fz_iniziale*100
dfw['F_ratio'] = dfw.Fz_peak/dfw.Fz_iniziale
dfw['dF'] = dfw['F_ratio'] - 1

mat = []
all_sk = np.unique(df_wear.sk)

for cc in all_sk:
    mat.append(df_wear[df_wear.sk==cc].materiale.values[0])

dfw['materiale'] = mat

# #reindex per leggere meglio i dati

features = ['sk', 'colata','materiale','n_prove','numero_provini_torniti',
       'speed', 'feed', 'doc','area','tempo_usura', 'std_wear_time', 
       'Fz_iniziale','std_dev_Fz', 'Fz_peak','dF_perc', 'F_ratio', 'dF',
       'C', 'S', 'P', 'Si', 'Mn','Cr', 'Ni', 'Mo', 'Cu', 'Sn', 'V', 'W', 'Co', 'Ti', 'N2', 'O2 ',
       'k2_oa', 'k2_os', 'k2_og', 
       'rm', 'rp02',
       ]

dfw = dfw[features]

#faccio un pò di pulizia 
new_features =  ['O2' if item == 'O2 ' else item for item in features]
new_features =  ['area_contatto' if item == 'area' else item for item in features]
new_features =  ['n_provini' if item == 'numero_provini_torniti' else item for item in features]



dfw.columns = new_features

# dfw = dfw.dropna()
dfw = dfw.reset_index()
dfw = dfw.drop('index',axis=1)

#salvo i dati come csv
dfw.to_pickle('/data/metalm/pickle/dbmm.pkl')

```

Stampo le features 

```{python print_info}
for ff in dfw.columns:
  print('%s' %ff)

```


```{r table}
tabella <- py$dfw
cas_kable(tabella, caption='database')
```

